# Intro

Consider two different image dataset that vary in terms of their domains or distributions (texture, viewpoint, appearence, etc). The smaller one being the labbeled and the larger, unlabeled. Can we train a model using these two datasets in a way that allow domain adaptation by training on one data distribution and testing on a different one. Adaptive matching allows to unify unsupervised domain adaptation, semi-supervised learning, and semi-supervised domain adaptation under one framework. Lets use our [vision dataset](/adamatch.ipynb) to find out if it really improves the model performance even when the labeled dataset is very small.

# References

https://arxiv.org/abs/2106.04732

https://keras.io/examples/vision/adamatch/

https://happywhale.com
